{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime, calendar\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "#from tensorflow.keras import layers, models\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "#본사출장자수 scaling 어떻게 할지 정하기\n",
    "#강수량 등도 어떻게 정규화할지 정하기\n",
    "#여러 feature등 다듬기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_CrossValidation(train_x, train_y, num, models, weights, reg=True, random_state=42, minmax=False):\n",
    "    \n",
    "    ##모델은 반드시 [model1, model2, ...]의 리스트형식이어야 합니다.\n",
    "    ##모델을 한 개만 줄 시 [models], [weights] 형식이어야 함.\n",
    "    n_models = len(models)\n",
    "    \n",
    "    if sum(weights) > 1.:\n",
    "        return print(\"weight의 합이 1을 초과합니다.\")\n",
    "    if sum(weights) != 1. and reg==False:\n",
    "        return print('reg=False인데, weight합이 1이 아닙니다.')\n",
    "    \n",
    "    n_weights = len(weights)\n",
    "    if n_models != n_weights:\n",
    "        return print(\"weight와 model의 개수가 다릅니다.\")\n",
    "    \n",
    "    \n",
    "    kf = KFold(n_splits=num, random_state=random_state)\n",
    "    kf.get_n_splits(train_x)\n",
    "    mae = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        \n",
    "        X_train = copy.deepcopy(train_x.iloc[train_index])\n",
    "        X_valid = copy.deepcopy(train_x.iloc[test_index])\n",
    "        Y_train = copy.deepcopy(train_y.iloc[train_index])\n",
    "        Y_valid = copy.deepcopy(train_y.iloc[test_index])\n",
    "        \n",
    "        try:\n",
    "            X_train['강수량'] = X_train['점심강수량']\n",
    "            X_valid['강수량'] = X_valid['점심강수량']\n",
    "            del X_train['점심강수량'], X_valid['점심강수량']\n",
    "        except:\n",
    "            X_train['강수량'] = X_train['저녁강수량']\n",
    "            X_valid['강수량'] = X_valid['저녁강수량']\n",
    "            del X_train['저녁강수량'], X_valid['저녁강수량']\n",
    "        \n",
    "        \n",
    "        \n",
    "        if minmax == False:\n",
    "            \n",
    "            to_bias = X_train['본사출근자수'].mean()\n",
    "            to_scale = X_train['본사출근자수'].std()\n",
    "            covid_bias = X_train['Covid19'].mean()\n",
    "            covid_scale = X_train['Covid19'].std()\n",
    "            dust10_bias = X_train['PM10'].mean()\n",
    "            dust10_scale = X_train['PM10'].std()\n",
    "            #holy_bias = X_train['본사휴가자수'].mean()\n",
    "            #holy_scale = X_train['본사휴가자수'].std()\n",
    "            #out_bias = X_train['본사출장자수'].mean()\n",
    "            #out_scale = X_train['본사출장자수'].std()\n",
    "            TO_bias = X_train['본사정원수'].mean()\n",
    "            TO_scale = X_train['본사정원수'].std()\n",
    "            #excess_bias = X_train['본사시간외근무명령서승인건수'].mean()\n",
    "            #excess_scale = X_train['본사시간외근무명령서승인건수'].std()\n",
    "            #home_bias = X_train['현본사소속재택근무자수'].mean()\n",
    "            #home_scale = X_train['현본사소속재택근무자수'].std()\n",
    "            rain_bias = X_train['강수량'].mean()\n",
    "            rain_scale = X_train['강수량'].std()\n",
    "\n",
    "            \n",
    "        else:\n",
    "            to_bias = X_train['본사출근자수'].min()\n",
    "            to_scale = X_train['본사출근자수'].max() - X_train['본사출근자수'].min()\n",
    "            covid_bias = X_train['Covid19'].min()\n",
    "            covid_scale = X_train['Covid19'].max() - X_train['Covid19'].min()\n",
    "            dust10_bias = X_train['PM10'].min()\n",
    "            dust10_scale = X_train['PM10'].max() - X_train['PM10'].min()\n",
    "            TO_bias = X_train['본사정원수'].min()\n",
    "            TO_scale = X_train['본사정원수'].max() - X_train['본사정원수'].min()\n",
    "            rain_bias = X_train['강수량'].min()\n",
    "            rain_scale = X_train['강수량'].max() - X_train['강수량'].min()\n",
    "            \n",
    "        if to_scale != 0:\n",
    "            X_train['본사출근자수'] = (X_train['본사출근자수'] - to_bias) / to_scale\n",
    "            X_valid['본사출근자수'] = (X_valid['본사출근자수'] - to_bias) / to_scale\n",
    "        \n",
    "\n",
    "        if covid_scale != 0:\n",
    "            X_train['Covid19'] = (X_train['Covid19'] - covid_bias) / covid_scale\n",
    "            X_valid['Covid19'] = (X_valid['Covid19'] - covid_bias) / covid_scale\n",
    "            \n",
    "        if dust10_scale != 0:\n",
    "            X_train['PM10'] = (X_train['PM10'] - dust10_bias) / dust10_scale\n",
    "            X_valid['PM10'] = (X_valid['PM10'] - dust10_bias) / dust10_scale            \n",
    "            \n",
    "        #if holy_scale != 0:\n",
    "        #    X_train['본사휴가자수'] = (X_train['본사휴가자수'] - holy_bias) / holy_scale\n",
    "        #    X_valid['본사휴가자수'] = (X_valid['본사휴가자수'] - holy_bias) / holy_scale\n",
    "        #\n",
    "        #if out_scale != 0:\n",
    "        #    X_train['본사출장자수'] = (X_train['본사출장자수'] - out_bias) / out_scale\n",
    "        #    X_valid['본사출장자수'] = (X_valid['본사출장자수'] - out_bias) / out_scale\n",
    "        #\n",
    "        if TO_scale != 0:\n",
    "            X_train['본사정원수'] = (X_train['본사정원수'] - TO_bias) / TO_scale\n",
    "            X_valid['본사정원수'] = (X_valid['본사정원수'] - TO_bias) / TO_scale\n",
    "        #\n",
    "        #if excess_scale != 0:\n",
    "        #    X_train['본사시간외근무명령서승인건수'] = (X_train['본사시간외근무명령서승인건수'] - excess_bias) / excess_scale\n",
    "        #    X_valid['본사시간외근무명령서승인건수'] = (X_valid['본사시간외근무명령서승인건수'] - excess_bias) / excess_scale\n",
    "        #    \n",
    "        #if home_scale != 0:\n",
    "        #    X_train['현본사소속재택근무자수'] = (X_train['현본사소속재택근무자수'] - home_bias) / home_scale\n",
    "        #    X_valid['현본사소속재택근무자수'] = (X_valid['현본사소속재택근무자수'] - home_bias) / home_scale\n",
    "            \n",
    "        if rain_scale != 0:\n",
    "            X_train['강수량'] = (X_train['강수량'] - rain_bias) / rain_scale\n",
    "            X_valid['강수량'] = (X_valid['강수량'] - rain_bias) / rain_scale    \n",
    "            \n",
    "        if reg:\n",
    "            regmodel = sm.OLS(Y_train, X_train, missing='drop').fit()\n",
    "        fitted_model = [models[i].fit(X_train, Y_train) for i in range(n_models)]         \n",
    "                 \n",
    "        \n",
    "        #model1.fit(X_train, Y_train)\n",
    "        #model2.fit(X_train, Y_train)\n",
    "        y_pred=0\n",
    "        for i in range(n_models):\n",
    "            y_pred += weights[i] * fitted_model[i].predict(X_valid)\n",
    "        \n",
    "        if reg:\n",
    "            y_pred += (1 - sum(weights)) * (regmodel.predict(X_valid))\n",
    "        #y_pred = y_pred * train_x_lunch['본사출근자수'][test_index]\n",
    "        #y_real = Y_valid * train_x_lunch['본사출근자수'][test_index]\n",
    "        y_pred = y_pred * train_x_lunch['본사정원수'][test_index]\n",
    "        y_real = Y_valid * train_x_lunch['본사정원수'][test_index]\n",
    "        \n",
    "        loss = np.mean(np.abs(y_real - y_pred))\n",
    "        mae.append(loss)\n",
    "    \n",
    "    return mae, np.mean(mae)\n",
    "\n",
    "\n",
    "def week_of_month(dt):\n",
    "\n",
    "    first_day = dt.replace(day=1)\n",
    "\n",
    "    dom = dt.day\n",
    "    adjusted_dom = dom + first_day.weekday()\n",
    "\n",
    "    return str(int(np.ceil(adjusted_dom/7.0)))\n",
    "\n",
    "\n",
    "def MunhwaDay(row):\n",
    "    if len(row['석식메뉴']) < 20 or row['석식계'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def CleanMenuList(row):\n",
    "    if row['석식계'] == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return row['석식메뉴']\n",
    "        \n",
    "    \n",
    "def GetMenuList(row):\n",
    "    row = row.split()\n",
    "    result = []\n",
    "    for food in row:\n",
    "        if '(' in food and ')' in food and ':' in food:\n",
    "            continue\n",
    "        \n",
    "        if '*' in food:\n",
    "            result.extend(food.split('*'))\n",
    "            continue\n",
    "        \n",
    "        food = re.sub('\\(New\\)', '', food)\n",
    "        #food = re.sub('/\\w+', '', food)\n",
    "        \n",
    "        result.append(food)\n",
    "    return result\n",
    "\n",
    "\n",
    "def TempClass(row):\n",
    "    if row >= 30:\n",
    "        return 'temp30+'\n",
    "    elif row >= 25:\n",
    "        return 'temp25+'\n",
    "    elif row >= 20:\n",
    "        return 'temp20+'\n",
    "    elif row >= 15:\n",
    "        return 'temp15+'\n",
    "    elif row >= 10:\n",
    "        return 'temp10+'\n",
    "    elif row >= 5:\n",
    "        return 'temp5+'\n",
    "    elif row >= 0:\n",
    "        return 'temp0+'\n",
    "    elif row >= -5:\n",
    "        return 'temp-5+'\n",
    "    elif row >= -10:\n",
    "        return 'temp-10+'\n",
    "    elif row >= -15:\n",
    "        return 'temp-15+'\n",
    "    elif row >= -20:\n",
    "        return 'temp-20+'\n",
    "    else:\n",
    "        return 'temp-20-'\n",
    "    \n",
    "\n",
    "    \n",
    "def PreHolyday(row, pre_hol):\n",
    "    if row in pre_hol.values:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def Temp30Class(row):\n",
    "    if row >= 30:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def MenuEncoding(row, menu_list1, menu_list2):\n",
    "    result = []\n",
    "    for food in row:\n",
    "        try:\n",
    "            result.append(menu_list1[food])\n",
    "        except:\n",
    "            continue\n",
    "    for food in row:\n",
    "        try:\n",
    "            result.append(menu_list2[food])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "def MakeDTM(row):\n",
    "    if len(row) == 0:\n",
    "        return pd.Series(0, index=range(103))\n",
    "    res = np.where(encoder.transform(np.array(row).reshape(-1,1)).toarray().sum(axis=0) >= 1, 1., 0.)\n",
    "    return pd.Series(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.index = pd.to_datetime(train_data['일자'])\n",
    "del train_data['조식메뉴'], train_data['일자']\n",
    "train_data.loc['2018-06-01']['요일'] = '금'\n",
    "\n",
    "\n",
    "cases = pd.read_csv('일일코로나확진자.csv')\n",
    "cases = cases[(cases['Entity'] == 'South Korea')].iloc[:, [2, 3]].reset_index(drop=True)\n",
    "cases.index = pd.to_datetime(cases['Day'])\n",
    "del cases['Day']\n",
    "cases.columns = ['확진자수']\n",
    "cases = cases[cases.index < '2021-04-10']\n",
    "temp = cases.values.flatten().tolist()\n",
    "temp.pop()\n",
    "temp[0:0] = [0.]\n",
    "cases['확진자수'] = temp\n",
    "#cases = cases.rolling(5).mean().fillna(0)\n",
    "#cases['확진자수'] = np.where(cases['확진자수'] == 0., 0., 1 / (1 + np.exp(- 1 / 100 * cases['확진자수'] + 3)))\n",
    "#cases = cases.rolling(7).mean().fillna(0)\n",
    "cases.columns = ['Covid19']\n",
    "del temp\n",
    "\n",
    "temp = pd.read_csv('진주시_기온정보.csv', encoding='euc-kr')\n",
    "temp.index = pd.to_datetime(temp['날짜'])\n",
    "del temp['날짜'], temp['지점'], temp['최저기온(℃)']\n",
    "\n",
    "rain = pd.read_csv('TimeRain.csv')\n",
    "rain.index = pd.to_datetime(rain['날짜'])\n",
    "del rain['날짜'], rain['강수량']\n",
    "\n",
    "dust = pd.read_csv('fine_dust.txt', sep='\\t')\n",
    "dust.index = pd.to_datetime(dust['날짜'])\n",
    "del dust['날짜'], dust['PM2.5']\n",
    "\n",
    "\n",
    "train_data = pd.concat([train_data, temp, cases, rain, dust], axis=1)\n",
    "train_data = train_data[~train_data['본사정원수'].isnull()].fillna(0.)\n",
    "\n",
    "\n",
    "    \n",
    "train_data['개월'] = [f'{date.month}월' for date in train_data.index]\n",
    "train_data['주차'] = [f'{week_of_month(date)}주차' for date in train_data.index]\n",
    "train_data['문화day'] = train_data.apply(lambda row : MunhwaDay(row), axis=1)\n",
    "train_data['석식메뉴'] = train_data.apply(lambda row : CleanMenuList(row), axis=1)\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.index = pd.to_datetime(test_data['일자'])\n",
    "del test_data['조식메뉴'], test_data['일자']\n",
    "test_data = pd.concat([test_data, temp, cases, rain, dust], axis=1)\n",
    "test_data = test_data[~test_data['본사정원수'].isnull()].fillna(0.)\n",
    "test_data['개월'] = [f'{date.month}월' for date in test_data.index]\n",
    "test_data['주차'] = [f'{week_of_month(date)}주차' for date in test_data.index]\n",
    "test_data['문화day'] = [0 for i in range(len(test_data))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "whole_df = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "\n",
    "#   \n",
    "whole_df['본사출근자수'] = whole_df['본사정원수'] - whole_df['본사휴가자수'] - whole_df['현본사소속재택근무자수'] \\\n",
    "                         - whole_df['본사출장자수']\n",
    "\n",
    "whole_df['본사휴가율'] = whole_df['본사휴가자수'] / whole_df['본사정원수']\n",
    "whole_df['본사출장율'] = whole_df['본사출장자수'] / whole_df['본사정원수']\n",
    "whole_df['본사재택근무율'] = whole_df['현본사소속재택근무자수'] / whole_df['본사정원수']\n",
    "\n",
    "whole_df['시간외근무율'] = whole_df['본사시간외근무명령서승인건수'] / whole_df['본사출근자수']\n",
    "\n",
    "whole_df['중식 참여율'] = whole_df['중식계'] / whole_df['본사정원수']#\n",
    "whole_df['석식 참여율'] = whole_df['석식계'] / whole_df['본사정원수']#\n",
    "whole_df['평균기온'] = whole_df['평균기온(℃)'].apply(TempClass)\n",
    "whole_df['최고기온30+'] = whole_df['최고기온(℃)'].apply(Temp30Class)\n",
    "whole_df['중식메뉴'] = whole_df['중식메뉴'].apply(GetMenuList)\n",
    "whole_df['석식메뉴'] = whole_df['석식메뉴'].apply(GetMenuList)\n",
    "\n",
    "del whole_df['본사휴가자수']#, whole_df['본사정원수']\n",
    "del whole_df['현본사소속재택근무자수'], whole_df['본사출장자수']\n",
    "del whole_df['본사시간외근무명령서승인건수']\n",
    "del whole_df['중식계'], whole_df['석식계']\n",
    "del whole_df['평균기온(℃)'], whole_df['최고기온(℃)']\n",
    "    \n",
    "\n",
    "                                                \n",
    "pre_hol = pd.read_csv('pre_holiday.txt', encoding='utf8')\n",
    "pre_hol = pd.to_datetime(pre_hol['공휴일전평일'])\n",
    "whole_df['pre공휴일'] = [PreHolyday(date, pre_hol) for date in whole_df.index]\n",
    "menu = whole_df[['중식메뉴', '석식메뉴']]\n",
    "del whole_df['중식메뉴'], whole_df['석식메뉴']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##menu_label = pd.read_csv('menu_label.csv').fillna('없음')\n",
    "#menu_label = pd.read_csv('menulabeling.csv').fillna('없음')\n",
    "#menu_label['label1'] = menu_label['label1'].apply(lambda row : row.strip())\n",
    "#menu_label['label2'] = menu_label['label2'].apply(lambda row : row.strip())\n",
    "#menu_list1 = {}\n",
    "#for _, row in menu_label[['menu', 'label1']].iterrows():\n",
    "#    menu_list1[row['menu']] = row['label1']\n",
    "#    \n",
    "#menu_list2 = {}\n",
    "#for _, row in menu_label[['menu', 'label2']].iterrows():\n",
    "#    menu_list2[row['menu']] = row['label2']\n",
    "##    \n",
    "#menu['중식인코딩'] = menu['중식메뉴'].apply(lambda row : MenuEncoding(row, menu_list1, menu_list2))\n",
    "#menu['석식인코딩'] = menu['석식메뉴'].apply(lambda row : MenuEncoding(row, menu_list1, menu_list2))\n",
    "##\n",
    "#encoder = OneHotEncoder()\n",
    "#menu_list = menu_label['label1'].unique().tolist()\n",
    "#menu_list.extend(menu_label['label2'].unique().tolist())\n",
    "#\n",
    "#menu_list = [[food] for food in menu_list]\n",
    "#encoder.fit(menu_list)\n",
    "##\n",
    "#lunch_menu = menu['중식인코딩'].apply(MakeDTM)\n",
    "#dinner_menu = menu['석식인코딩'].apply(MakeDTM)\n",
    "#\n",
    "\n",
    "day_dummy = pd.get_dummies(whole_df['요일'])\n",
    "month_dummy = pd.get_dummies(whole_df['개월'])\n",
    "week_dummy = pd.get_dummies(whole_df['주차'])\n",
    "avgtemp_dummy = pd.get_dummies(whole_df[['평균기온']])\n",
    "\n",
    "whole_df = pd.concat([whole_df, day_dummy, month_dummy, week_dummy,\n",
    "                      avgtemp_dummy], axis=1)\n",
    "drop_cols = ['요일', '개월', '주차', '평균기온']\n",
    "whole_df.drop(drop_cols, axis=1, inplace=True)\n",
    "whole_df = sm.add_constant(whole_df)\n",
    "train_y_lunch = whole_df['중식 참여율'].dropna()\n",
    "train_y_dinner = whole_df['석식 참여율'].dropna()\n",
    "del whole_df['중식 참여율'], whole_df['석식 참여율']\n",
    "whole_df['4주x금요일'] = whole_df['4주차'] * whole_df['금']\n",
    "whole_df['timedelta'] = (np.array([(whole_df.index[i] - whole_df.index[i-1]).days for i in range(1, len(whole_df))] + [3]) - 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_x, test_x = copy.deepcopy(whole_df.iloc[:len(train_data),:]), copy.deepcopy(whole_df.iloc[len(train_data):,:])\n",
    "train_x.drop(datetime.datetime(2018,6,22), axis=0, inplace=True)\n",
    "train_y_lunch.drop(datetime.datetime(2018,6,22), axis=0, inplace=True)\n",
    "train_y_dinner.drop(datetime.datetime(2018,6,22), axis=0, inplace=True)\n",
    "\n",
    "train_x_lunch, train_x_dinner = copy.deepcopy(train_x), copy.deepcopy(train_x)\n",
    "del train_x_lunch['저녁강수량'], train_x_dinner['점심강수량']\n",
    "test_x_lunch, test_x_dinner = copy.deepcopy(test_x), copy.deepcopy(test_x)\n",
    "del test_x_lunch['저녁강수량'], test_x_dinner['점심강수량']\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#train_x_lunch = pd.concat([train_x_lunch, lunch_menu], axis=1).dropna()\n",
    "#test_x_lunch = pd.concat([test_x_lunch, lunch_menu], axis=1).dropna()\n",
    "#train_x_dinner = pd.concat([train_x_dinner, dinner_menu], axis=1).dropna()\n",
    "#test_x_dinner = pd.concat([test_x_dinner, dinner_menu], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "model2 = XGBRegressor(objective='reg:squarederror', n_estimators=100,\n",
    "                      learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                      colsample_bytree=1, max_depth=7, random_state=42)\n",
    "model3 = Ridge(alpha=2.5, fit_intercept=True, random_state=42, normalize=False)\n",
    "model4 = BaggingRegressor(random_state=30)\n",
    "model5 = AdaBoostRegressor(random_state=42)\n",
    "model6 = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([60.3636320934053,\n",
       "  64.04428826941684,\n",
       "  75.42639002663154,\n",
       "  68.24943885676129,\n",
       "  52.49862495895019,\n",
       "  72.85318660096195,\n",
       "  82.28386440728579,\n",
       "  71.6695155215546,\n",
       "  76.68914577499201,\n",
       "  73.80093142575555,\n",
       "  83.10250954151726,\n",
       "  104.43454050205796,\n",
       "  90.68977551357395,\n",
       "  83.2174524706854,\n",
       "  93.53876349304453],\n",
       " 76.85747063043961)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_CrossValidation(train_x=train_x_lunch, \n",
    "                       train_y=train_y_lunch,\n",
    "                       num=15,\n",
    "                       models=[model1, model2, model3, model4, model6],\n",
    "                       weights=[0.2, 0.2, 0.1, 0.1, 0.4],\n",
    "                       minmax=False,\n",
    "                       reg=False)\n",
    "#output : 76.28\n",
    "\n",
    "#model1 : 80.72\n",
    "#model2 : 79.29\n",
    "#model3 : 87.21\n",
    "#model4 : 86.28\n",
    "#model5: 98.07\n",
    "#model6 : 78.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([49.65847346161556,\n",
       "  48.69312180983775,\n",
       "  51.5056032781334,\n",
       "  49.4388011073643,\n",
       "  38.25565141644013,\n",
       "  51.22920797176222,\n",
       "  46.07290659086086,\n",
       "  49.69951298799195,\n",
       "  46.589129393491746,\n",
       "  46.64721840492652,\n",
       "  64.67193775723375,\n",
       "  57.256906843585135,\n",
       "  71.25843798106185,\n",
       "  53.167710434890786,\n",
       "  64.70040875752639],\n",
       " 52.58966854644816)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_CrossValidation(train_x=train_x_dinner, \n",
    "                       train_y=train_y_dinner,\n",
    "                       num=15,\n",
    "                       models=[model1, model2, model4, model3, model6],\n",
    "                       weights=[0.2, 0.2, 0.1, 0.1, 0.4],\n",
    "                       minmax=False,\n",
    "                       reg=False)\n",
    "#output : 52.47\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실제 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.index = pd.to_datetime(train_data['일자'])\n",
    "del train_data['조식메뉴'], train_data['일자']\n",
    "train_data.loc['2018-06-01']['요일'] = '금'\n",
    "\n",
    "\n",
    "cases = pd.read_csv('일일코로나확진자.csv')\n",
    "cases = cases[(cases['Entity'] == 'South Korea')].iloc[:, [2, 3]].reset_index(drop=True)\n",
    "cases.index = pd.to_datetime(cases['Day'])\n",
    "del cases['Day']\n",
    "cases.columns = ['확진자수']\n",
    "cases = cases[cases.index < '2021-04-10']\n",
    "temp = cases.values.flatten().tolist()\n",
    "temp.pop()\n",
    "temp[0:0] = [0.]\n",
    "cases['확진자수'] = temp\n",
    "#cases = cases.rolling(5).mean().fillna(0)\n",
    "#cases['확진자수'] = np.where(cases['확진자수'] == 0., 0., 1 / (1 + np.exp(- 1 / 100 * cases['확진자수'] + 3)))\n",
    "#cases = cases.rolling(7).mean().fillna(0)\n",
    "cases.columns = ['Covid19']\n",
    "del temp\n",
    "\n",
    "temp = pd.read_csv('진주시_기온정보.csv', encoding='euc-kr')\n",
    "temp.index = pd.to_datetime(temp['날짜'])\n",
    "del temp['날짜'], temp['지점'], temp['최저기온(℃)']\n",
    "\n",
    "rain = pd.read_csv('TimeRain.csv')\n",
    "rain.index = pd.to_datetime(rain['날짜'])\n",
    "del rain['날짜'], rain['강수량']\n",
    "\n",
    "dust = pd.read_csv('fine_dust.txt', sep='\\t')\n",
    "dust.index = pd.to_datetime(dust['날짜'])\n",
    "del dust['날짜'], dust['PM2.5']\n",
    "\n",
    "\n",
    "train_data = pd.concat([train_data, temp, cases, rain, dust], axis=1)\n",
    "train_data = train_data[~train_data['본사정원수'].isnull()].fillna(0.)\n",
    "\n",
    "\n",
    "    \n",
    "train_data['개월'] = [f'{date.month}월' for date in train_data.index]\n",
    "train_data['주차'] = [f'{week_of_month(date)}주차' for date in train_data.index]\n",
    "train_data['문화day'] = train_data.apply(lambda row : MunhwaDay(row), axis=1)\n",
    "train_data['석식메뉴'] = train_data.apply(lambda row : CleanMenuList(row), axis=1)\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.index = pd.to_datetime(test_data['일자'])\n",
    "del test_data['조식메뉴'], test_data['일자']\n",
    "test_data = pd.concat([test_data, temp, cases, rain, dust], axis=1)\n",
    "test_data = test_data[~test_data['본사정원수'].isnull()].fillna(0.)\n",
    "test_data['개월'] = [f'{date.month}월' for date in test_data.index]\n",
    "test_data['주차'] = [f'{week_of_month(date)}주차' for date in test_data.index]\n",
    "test_data['문화day'] = [0 for i in range(len(test_data))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "whole_df = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "\n",
    "#   \n",
    "whole_df['본사출근자수'] = whole_df['본사정원수'] - whole_df['본사휴가자수'] - whole_df['현본사소속재택근무자수'] \\\n",
    "                         - whole_df['본사출장자수']\n",
    "\n",
    "whole_df['본사휴가율'] = whole_df['본사휴가자수'] / whole_df['본사정원수']\n",
    "whole_df['본사출장율'] = whole_df['본사출장자수'] / whole_df['본사정원수']\n",
    "whole_df['본사재택근무율'] = whole_df['현본사소속재택근무자수'] / whole_df['본사정원수']\n",
    "\n",
    "whole_df['시간외근무율'] = whole_df['본사시간외근무명령서승인건수'] / whole_df['본사출근자수']\n",
    "\n",
    "whole_df['중식 참여율'] = whole_df['중식계'] / whole_df['본사출근자수']##\n",
    "whole_df['석식 참여율'] = whole_df['석식계'] / whole_df['본사출근자수']##\n",
    "whole_df['평균기온'] = whole_df['평균기온(℃)'].apply(TempClass)\n",
    "whole_df['최고기온30+'] = whole_df['최고기온(℃)'].apply(Temp30Class)\n",
    "whole_df['중식메뉴'] = whole_df['중식메뉴'].apply(GetMenuList)\n",
    "whole_df['석식메뉴'] = whole_df['석식메뉴'].apply(GetMenuList)\n",
    "\n",
    "del whole_df['본사휴가자수'], whole_df['본사정원수']\n",
    "del whole_df['현본사소속재택근무자수'], whole_df['본사출장자수']\n",
    "del whole_df['본사시간외근무명령서승인건수']\n",
    "del whole_df['중식계'], whole_df['석식계']\n",
    "del whole_df['평균기온(℃)'], whole_df['최고기온(℃)']\n",
    "    \n",
    "\n",
    "                                                \n",
    "pre_hol = pd.read_csv('pre_holiday.txt', encoding='utf8')\n",
    "pre_hol = pd.to_datetime(pre_hol['공휴일전평일'])\n",
    "whole_df['pre공휴일'] = [PreHolyday(date, pre_hol) for date in whole_df.index]\n",
    "menu = whole_df[['중식메뉴', '석식메뉴']]\n",
    "del whole_df['중식메뉴'], whole_df['석식메뉴']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#menu_label = pd.read_csv('menu_label.csv').fillna('없음')\n",
    "menu_label = pd.read_csv('menulabeling.csv').fillna('없음')\n",
    "menu_label['label1'] = menu_label['label1'].apply(lambda row : row.strip())\n",
    "menu_label['label2'] = menu_label['label2'].apply(lambda row : row.strip())\n",
    "menu_list1 = {}\n",
    "for _, row in menu_label[['menu', 'label1']].iterrows():\n",
    "    menu_list1[row['menu']] = row['label1']\n",
    "    \n",
    "menu_list2 = {}\n",
    "for _, row in menu_label[['menu', 'label2']].iterrows():\n",
    "    menu_list2[row['menu']] = row['label2']\n",
    "#    \n",
    "menu['중식인코딩'] = menu['중식메뉴'].apply(lambda row : MenuEncoding(row, menu_list1, menu_list2))\n",
    "menu['석식인코딩'] = menu['석식메뉴'].apply(lambda row : MenuEncoding(row, menu_list1, menu_list2))\n",
    "#\n",
    "encoder = OneHotEncoder()\n",
    "menu_list = menu_label['label1'].unique().tolist()\n",
    "menu_list.extend(menu_label['label2'].unique().tolist())\n",
    "\n",
    "menu_list = [[food] for food in menu_list]\n",
    "encoder.fit(menu_list)\n",
    "#\n",
    "lunch_menu = menu['중식인코딩'].apply(MakeDTM)\n",
    "dinner_menu = menu['석식인코딩'].apply(MakeDTM)\n",
    "\n",
    "\n",
    "day_dummy = pd.get_dummies(whole_df['요일'])\n",
    "month_dummy = pd.get_dummies(whole_df['개월'])\n",
    "week_dummy = pd.get_dummies(whole_df['주차'])\n",
    "avgtemp_dummy = pd.get_dummies(whole_df[['평균기온']])\n",
    "\n",
    "whole_df = pd.concat([whole_df, day_dummy, month_dummy, week_dummy,\n",
    "                      avgtemp_dummy], axis=1)\n",
    "drop_cols = ['요일', '개월', '주차', '평균기온']\n",
    "whole_df.drop(drop_cols, axis=1, inplace=True)\n",
    "whole_df = sm.add_constant(whole_df)\n",
    "train_y_lunch = whole_df['중식 참여율'].dropna()\n",
    "train_y_dinner = whole_df['석식 참여율'].dropna()\n",
    "del whole_df['중식 참여율'], whole_df['석식 참여율']\n",
    "whole_df['4주x금요일'] = whole_df['4주차'] * whole_df['금']\n",
    "whole_df['timedelta'] = (np.array([(whole_df.index[i] - whole_df.index[i-1]).days for i in range(1, len(whole_df))] + [3]) - 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_x, test_x = copy.deepcopy(whole_df.iloc[:len(train_data),:]), copy.deepcopy(whole_df.iloc[len(train_data):,:])\n",
    "train_x.drop(datetime.datetime(2018,6,22), axis=0, inplace=True)\n",
    "train_y_lunch.drop(datetime.datetime(2018,6,22), axis=0, inplace=True)\n",
    "train_y_dinner.drop(datetime.datetime(2018,6,22), axis=0, inplace=True)\n",
    "\n",
    "to_bias = train_x['본사출근자수'].min()\n",
    "to_scale = train_x['본사출근자수'].max() - train_x['본사출근자수'].min()\n",
    "covid_bias = train_x['Covid19'].min()\n",
    "covid_scale =  train_x['Covid19'].max() -  train_x['Covid19'].min()\n",
    "dust10_bias = train_x['PM10'].min()\n",
    "dust10_scale = train_x['PM10'].max() - train_x['PM10'].min()\n",
    "#holy_bias = train_x['본사휴가자수'].mean()\n",
    "#holy_scale = train_x['본사휴가자수'].std()\n",
    "#out_bias = train_x['본사출장자수'].mean()\n",
    "#out_scale = train_x['본사출장자수'].std()\n",
    "#TO_bias = train_x['본사정원수'].min()\n",
    "#TO_scale = train_x['본사정원수'].max() - train_x['본사정원수'].min()\n",
    "#excess_bias = train_x['본사시간외근무명령서승인건수'].mean()\n",
    "#excess_scale = train_x['본사시간외근무명령서승인건수'].std()\n",
    "#home_bias = train_x['현본사소속재택근무자수'].mean()\n",
    "#home_scale = train_x['현본사소속재택근무자수'].std()\n",
    "lrain_bias = train_x['점심강수량'].min()\n",
    "lrain_scale = train_x['점심강수량'].max() - train_x['점심강수량'].min()\n",
    "drain_bias = train_x['저녁강수량'].min()\n",
    "drain_scale = train_x['저녁강수량'].max() - train_x['저녁강수량'].min()\n",
    "\n",
    "if to_scale != 0:\n",
    "    train_x['본사출근자수'] = (train_x['본사출근자수'] - to_bias) / to_scale\n",
    "    test_x['본사출근자수'] = (test_x['본사출근자수'] - to_bias) / to_scale\n",
    "\n",
    "\n",
    "if covid_scale != 0:\n",
    "    train_x['Covid19'] = (train_x['Covid19'] - covid_bias) / covid_scale\n",
    "    test_x['Covid19'] = (test_x['Covid19'] - covid_bias) / covid_scale\n",
    "    \n",
    "if dust10_scale != 0:\n",
    "    train_x['PM10'] = (train_x['PM10'] - dust10_bias) / dust10_scale\n",
    "    test_x['PM10'] = (test_x['PM10'] - dust10_bias) / dust10_scale            \n",
    "#    \n",
    "#if holy_scale != 0:\n",
    "#    train_x['본사휴가자수'] = (train_x['본사휴가자수'] - holy_bias) / holy_scale\n",
    "#    test_x['본사휴가자수'] = (test_x['본사휴가자수'] - holy_bias) / holy_scale\n",
    "#\n",
    "#if out_scale != 0:\n",
    "#    train_x['본사출장자수'] = (train_x['본사출장자수'] - out_bias) / out_scale\n",
    "#    test_x['본사출장자수'] = (test_x['본사출장자수'] - out_bias) / out_scale\n",
    "#\n",
    "#if TO_scale != 0:\n",
    "#    train_x['본사정원수'] = (train_x['본사정원수'] - TO_bias) / TO_scale\n",
    "#    test_x['본사정원수'] = (test_x['본사정원수'] - TO_bias) / TO_scale\n",
    "#\n",
    "#if excess_scale != 0:\n",
    "#    train_x['본사시간외근무명령서승인건수'] = (train_x['본사시간외근무명령서승인건수'] - excess_bias) / excess_scale\n",
    "#    test_x['본사시간외근무명령서승인건수'] = (test_x['본사시간외근무명령서승인건수'] - excess_bias) / excess_scale\n",
    "#    \n",
    "#if home_scale != 0:\n",
    "#    train_x['현본사소속재택근무자수'] = (train_x['현본사소속재택근무자수'] - home_bias) / home_scale\n",
    "#    test_x['현본사소속재택근무자수'] = (test_x['현본사소속재택근무자수'] - home_bias) / home_scale\n",
    "    \n",
    "if lrain_scale != 0:\n",
    "    train_x['점심강수량'] = (train_x['점심강수량'] - lrain_bias) / lrain_scale\n",
    "    test_x['점심강수량'] = (test_x['점심강수량'] - lrain_bias) / lrain_scale   \n",
    "\n",
    "if drain_scale != 0:\n",
    "    train_x['저녁강수량'] = (train_x['저녁강수량'] - drain_bias) / drain_scale\n",
    "    test_x['저녁강수량'] = (test_x['저녁강수량'] - drain_bias) / drain_scale   \n",
    "\n",
    "    \n",
    "\n",
    "train_x_lunch, train_x_dinner = copy.deepcopy(train_x), copy.deepcopy(train_x)\n",
    "del train_x_lunch['저녁강수량'], train_x_dinner['점심강수량']\n",
    "test_x_lunch, test_x_dinner = copy.deepcopy(test_x), copy.deepcopy(test_x)\n",
    "del test_x_lunch['저녁강수량'], test_x_dinner['점심강수량']\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "train_x_lunch = pd.concat([train_x_lunch, lunch_menu], axis=1).dropna()\n",
    "test_x_lunch = pd.concat([test_x_lunch, lunch_menu], axis=1).dropna()\n",
    "train_x_dinner = pd.concat([train_x_dinner, dinner_menu], axis=1).dropna()\n",
    "test_x_dinner = pd.concat([test_x_dinner, dinner_menu], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>중식 참여율</td>      <th>  R-squared:         </th> <td>   0.813</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.791</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   37.46</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 06 Jul 2021</td> <th>  Prob (F-statistic):</th> <td>1.11e-313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:40:50</td>     <th>  Log-Likelihood:    </th> <td>  2268.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1204</td>      <th>  AIC:               </th> <td>  -4284.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1078</td>      <th>  BIC:               </th> <td>  -3642.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   125</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>    0.5854</td> <td>    0.025</td> <td>   23.082</td> <td> 0.000</td> <td>    0.536</td> <td>    0.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covid19</th>       <td>    0.1164</td> <td>    0.014</td> <td>    8.455</td> <td> 0.000</td> <td>    0.089</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>점심강수량</th>         <td>    0.0933</td> <td>    0.022</td> <td>    4.300</td> <td> 0.000</td> <td>    0.051</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PM10</th>          <td>   -0.0166</td> <td>    0.009</td> <td>   -1.848</td> <td> 0.065</td> <td>   -0.034</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>문화day</th>         <td>   -0.0009</td> <td>    0.007</td> <td>   -0.117</td> <td> 0.907</td> <td>   -0.016</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>본사출근자수</th>        <td>   -0.4555</td> <td>    0.017</td> <td>  -27.411</td> <td> 0.000</td> <td>   -0.488</td> <td>   -0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>본사휴가율</th>         <td>   -1.1819</td> <td>    0.051</td> <td>  -23.249</td> <td> 0.000</td> <td>   -1.282</td> <td>   -1.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>본사출장율</th>         <td>   -2.4385</td> <td>    0.158</td> <td>  -15.416</td> <td> 0.000</td> <td>   -2.749</td> <td>   -2.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>본사재택근무율</th>       <td>   -0.6353</td> <td>    0.062</td> <td>  -10.204</td> <td> 0.000</td> <td>   -0.757</td> <td>   -0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>시간외근무율</th>        <td>    0.2022</td> <td>    0.026</td> <td>    7.691</td> <td> 0.000</td> <td>    0.151</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>최고기온30+</th>       <td>   -0.0026</td> <td>    0.006</td> <td>   -0.468</td> <td> 0.640</td> <td>   -0.013</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pre공휴일</th>        <td>   -0.0029</td> <td>    0.008</td> <td>   -0.362</td> <td> 0.717</td> <td>   -0.018</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>금</th>             <td>    0.0857</td> <td>    0.008</td> <td>   10.689</td> <td> 0.000</td> <td>    0.070</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>목</th>             <td>    0.0848</td> <td>    0.006</td> <td>   13.935</td> <td> 0.000</td> <td>    0.073</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>수</th>             <td>    0.1355</td> <td>    0.006</td> <td>   21.063</td> <td> 0.000</td> <td>    0.123</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>월</th>             <td>    0.1796</td> <td>    0.006</td> <td>   29.796</td> <td> 0.000</td> <td>    0.168</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>화</th>             <td>    0.0998</td> <td>    0.006</td> <td>   17.193</td> <td> 0.000</td> <td>    0.088</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10월</th>           <td>    0.0746</td> <td>    0.005</td> <td>   13.991</td> <td> 0.000</td> <td>    0.064</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11월</th>           <td>    0.0448</td> <td>    0.006</td> <td>    7.514</td> <td> 0.000</td> <td>    0.033</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12월</th>           <td>    0.0210</td> <td>    0.007</td> <td>    3.113</td> <td> 0.002</td> <td>    0.008</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1월</th>            <td>    0.0277</td> <td>    0.007</td> <td>    3.965</td> <td> 0.000</td> <td>    0.014</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2월</th>            <td>    0.0560</td> <td>    0.007</td> <td>    8.338</td> <td> 0.000</td> <td>    0.043</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3월</th>            <td>    0.0422</td> <td>    0.006</td> <td>    7.619</td> <td> 0.000</td> <td>    0.031</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4월</th>            <td>    0.0388</td> <td>    0.005</td> <td>    7.397</td> <td> 0.000</td> <td>    0.029</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5월</th>            <td>    0.0520</td> <td>    0.006</td> <td>    9.204</td> <td> 0.000</td> <td>    0.041</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6월</th>            <td>    0.0434</td> <td>    0.007</td> <td>    6.554</td> <td> 0.000</td> <td>    0.030</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7월</th>            <td>    0.0413</td> <td>    0.007</td> <td>    5.899</td> <td> 0.000</td> <td>    0.028</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8월</th>            <td>    0.0818</td> <td>    0.008</td> <td>   10.239</td> <td> 0.000</td> <td>    0.066</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9월</th>            <td>    0.0618</td> <td>    0.006</td> <td>    9.648</td> <td> 0.000</td> <td>    0.049</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1주차</th>           <td>    0.1035</td> <td>    0.006</td> <td>   18.103</td> <td> 0.000</td> <td>    0.092</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2주차</th>           <td>    0.1039</td> <td>    0.005</td> <td>   20.269</td> <td> 0.000</td> <td>    0.094</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3주차</th>           <td>    0.0994</td> <td>    0.005</td> <td>   19.503</td> <td> 0.000</td> <td>    0.089</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4주차</th>           <td>    0.0983</td> <td>    0.005</td> <td>   18.235</td> <td> 0.000</td> <td>    0.088</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5주차</th>           <td>    0.0980</td> <td>    0.005</td> <td>   18.529</td> <td> 0.000</td> <td>    0.088</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6주차</th>           <td>    0.0823</td> <td>    0.010</td> <td>    8.560</td> <td> 0.000</td> <td>    0.063</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp-10+</th> <td>    0.0654</td> <td>    0.014</td> <td>    4.712</td> <td> 0.000</td> <td>    0.038</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp-5+</th>  <td>    0.0596</td> <td>    0.007</td> <td>    8.058</td> <td> 0.000</td> <td>    0.045</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp0+</th>   <td>    0.0730</td> <td>    0.006</td> <td>   11.446</td> <td> 0.000</td> <td>    0.060</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp10+</th>  <td>    0.0597</td> <td>    0.006</td> <td>   10.103</td> <td> 0.000</td> <td>    0.048</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp15+</th>  <td>    0.0569</td> <td>    0.006</td> <td>    9.450</td> <td> 0.000</td> <td>    0.045</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp20+</th>  <td>    0.0563</td> <td>    0.007</td> <td>    8.623</td> <td> 0.000</td> <td>    0.044</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp25+</th>  <td>    0.0648</td> <td>    0.008</td> <td>    7.772</td> <td> 0.000</td> <td>    0.048</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp30+</th>  <td>    0.0845</td> <td>    0.017</td> <td>    5.036</td> <td> 0.000</td> <td>    0.052</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>평균기온_temp5+</th>   <td>    0.0652</td> <td>    0.006</td> <td>   10.804</td> <td> 0.000</td> <td>    0.053</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4주x금요일</th>        <td>   -0.0145</td> <td>    0.007</td> <td>   -2.102</td> <td> 0.036</td> <td>   -0.028</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>timedelta</th>     <td>   -0.0014</td> <td>    0.002</td> <td>   -0.785</td> <td> 0.433</td> <td>   -0.005</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>             <td>    0.0067</td> <td>    0.004</td> <td>    1.733</td> <td> 0.083</td> <td>   -0.001</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>             <td>   -0.0065</td> <td>    0.009</td> <td>   -0.720</td> <td> 0.472</td> <td>   -0.024</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>             <td>   -0.0064</td> <td>    0.010</td> <td>   -0.621</td> <td> 0.535</td> <td>   -0.026</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>             <td>   -0.0199</td> <td>    0.020</td> <td>   -0.980</td> <td> 0.327</td> <td>   -0.060</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>             <td>   -0.0029</td> <td>    0.008</td> <td>   -0.348</td> <td> 0.728</td> <td>   -0.019</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>             <td>    0.0258</td> <td>    0.013</td> <td>    2.014</td> <td> 0.044</td> <td>    0.001</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>             <td>   -0.0138</td> <td>    0.011</td> <td>   -1.229</td> <td> 0.219</td> <td>   -0.036</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>             <td>-3.473e-15</td> <td> 2.51e-16</td> <td>  -13.856</td> <td> 0.000</td> <td>-3.96e-15</td> <td>-2.98e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>             <td>    0.0052</td> <td>    0.010</td> <td>    0.545</td> <td> 0.586</td> <td>   -0.014</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>             <td>   -0.0143</td> <td>    0.010</td> <td>   -1.457</td> <td> 0.145</td> <td>   -0.034</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>            <td>   -0.0194</td> <td>    0.027</td> <td>   -0.715</td> <td> 0.475</td> <td>   -0.073</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>            <td>    0.0057</td> <td>    0.009</td> <td>    0.613</td> <td> 0.540</td> <td>   -0.013</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>            <td>    0.0120</td> <td>    0.013</td> <td>    0.911</td> <td> 0.362</td> <td>   -0.014</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th>            <td>    0.0064</td> <td>    0.005</td> <td>    1.250</td> <td> 0.211</td> <td>   -0.004</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th>            <td>   -0.0022</td> <td>    0.007</td> <td>   -0.334</td> <td> 0.739</td> <td>   -0.015</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th>            <td>    0.0043</td> <td>    0.022</td> <td>    0.195</td> <td> 0.846</td> <td>   -0.039</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th>            <td>   -0.0028</td> <td>    0.030</td> <td>   -0.096</td> <td> 0.924</td> <td>   -0.061</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th>            <td>   -0.0004</td> <td>    0.060</td> <td>   -0.006</td> <td> 0.995</td> <td>   -0.118</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18</th>            <td> 6.718e-16</td> <td> 8.01e-17</td> <td>    8.386</td> <td> 0.000</td> <td> 5.15e-16</td> <td> 8.29e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>19</th>            <td> 2.714e-15</td> <td> 1.73e-16</td> <td>   15.691</td> <td> 0.000</td> <td> 2.37e-15</td> <td> 3.05e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th>            <td>    0.0059</td> <td>    0.002</td> <td>    2.638</td> <td> 0.008</td> <td>    0.002</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21</th>            <td>    0.0059</td> <td>    0.002</td> <td>    2.638</td> <td> 0.008</td> <td>    0.002</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22</th>            <td>    0.0012</td> <td>    0.002</td> <td>    0.549</td> <td> 0.583</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23</th>            <td>    0.0053</td> <td>    0.005</td> <td>    1.106</td> <td> 0.269</td> <td>   -0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24</th>            <td>   -0.0211</td> <td>    0.011</td> <td>   -1.878</td> <td> 0.061</td> <td>   -0.043</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25</th>            <td>    0.0067</td> <td>    0.004</td> <td>    1.733</td> <td> 0.083</td> <td>   -0.001</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>26</th>            <td>    0.0012</td> <td>    0.026</td> <td>    0.044</td> <td> 0.965</td> <td>   -0.050</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>27</th>            <td>    0.0332</td> <td>    0.040</td> <td>    0.825</td> <td> 0.410</td> <td>   -0.046</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28</th>            <td>   -0.0017</td> <td>    0.024</td> <td>   -0.071</td> <td> 0.943</td> <td>   -0.049</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>29</th>            <td>    0.0078</td> <td>    0.013</td> <td>    0.579</td> <td> 0.563</td> <td>   -0.019</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>30</th>            <td>   -0.0219</td> <td>    0.035</td> <td>   -0.627</td> <td> 0.531</td> <td>   -0.091</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>31</th>            <td>   -0.0056</td> <td>    0.008</td> <td>   -0.749</td> <td> 0.454</td> <td>   -0.020</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>32</th>            <td>    0.0053</td> <td>    0.017</td> <td>    0.317</td> <td> 0.751</td> <td>   -0.027</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>33</th>            <td>    0.0118</td> <td>    0.010</td> <td>    1.182</td> <td> 0.237</td> <td>   -0.008</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>34</th>            <td>    0.0068</td> <td>    0.037</td> <td>    0.186</td> <td> 0.853</td> <td>   -0.065</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>35</th>            <td>   -0.0056</td> <td>    0.008</td> <td>   -0.702</td> <td> 0.483</td> <td>   -0.021</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>36</th>            <td>   -0.0036</td> <td>    0.025</td> <td>   -0.145</td> <td> 0.885</td> <td>   -0.053</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37</th>            <td>    0.0059</td> <td>    0.006</td> <td>    0.932</td> <td> 0.352</td> <td>   -0.007</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>38</th>            <td>   -0.0078</td> <td>    0.027</td> <td>   -0.287</td> <td> 0.774</td> <td>   -0.061</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>39</th>            <td>   -0.0103</td> <td>    0.011</td> <td>   -0.925</td> <td> 0.355</td> <td>   -0.032</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>40</th>            <td>    0.0211</td> <td>    0.024</td> <td>    0.889</td> <td> 0.374</td> <td>   -0.025</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>41</th>            <td>    0.0035</td> <td>    0.005</td> <td>    0.720</td> <td> 0.472</td> <td>   -0.006</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>42</th>            <td>   -0.0044</td> <td>    0.005</td> <td>   -0.879</td> <td> 0.379</td> <td>   -0.014</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>43</th>            <td>   -0.0079</td> <td>    0.005</td> <td>   -1.565</td> <td> 0.118</td> <td>   -0.018</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>44</th>            <td>    0.0012</td> <td>    0.002</td> <td>    0.549</td> <td> 0.583</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>45</th>            <td>   -0.0064</td> <td>    0.010</td> <td>   -0.621</td> <td> 0.535</td> <td>   -0.026</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>46</th>            <td>   -0.0012</td> <td>    0.019</td> <td>   -0.064</td> <td> 0.949</td> <td>   -0.038</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>47</th>            <td>    0.0216</td> <td>    0.029</td> <td>    0.736</td> <td> 0.462</td> <td>   -0.036</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>48</th>            <td>   -0.0041</td> <td>    0.027</td> <td>   -0.152</td> <td> 0.879</td> <td>   -0.057</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>49</th>            <td>    0.0552</td> <td>    0.037</td> <td>    1.484</td> <td> 0.138</td> <td>   -0.018</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>50</th>            <td>   -0.0049</td> <td>    0.008</td> <td>   -0.590</td> <td> 0.555</td> <td>   -0.021</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>51</th>            <td>   -0.0192</td> <td>    0.009</td> <td>   -2.132</td> <td> 0.033</td> <td>   -0.037</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>52</th>            <td>    0.0083</td> <td>    0.005</td> <td>    1.620</td> <td> 0.106</td> <td>   -0.002</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>53</th>            <td>   -0.0003</td> <td>    0.008</td> <td>   -0.039</td> <td> 0.969</td> <td>   -0.017</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>54</th>            <td>    0.0080</td> <td>    0.006</td> <td>    1.423</td> <td> 0.155</td> <td>   -0.003</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>55</th>            <td>   -0.0130</td> <td>    0.021</td> <td>   -0.622</td> <td> 0.534</td> <td>   -0.054</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>56</th>            <td> 1.755e-05</td> <td>    0.005</td> <td>    0.004</td> <td> 0.997</td> <td>   -0.009</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>57</th>            <td>   -0.0177</td> <td>    0.032</td> <td>   -0.560</td> <td> 0.576</td> <td>   -0.080</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>58</th>            <td>    0.0224</td> <td>    0.058</td> <td>    0.385</td> <td> 0.701</td> <td>   -0.092</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>59</th>            <td> 1.044e-17</td> <td> 2.06e-17</td> <td>    0.508</td> <td> 0.612</td> <td>-2.99e-17</td> <td> 5.08e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>60</th>            <td>    0.0131</td> <td>    0.010</td> <td>    1.266</td> <td> 0.206</td> <td>   -0.007</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>61</th>            <td>    0.0101</td> <td>    0.009</td> <td>    1.159</td> <td> 0.247</td> <td>   -0.007</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>62</th>            <td>   -0.0144</td> <td>    0.009</td> <td>   -1.632</td> <td> 0.103</td> <td>   -0.032</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>63</th>            <td>    0.0067</td> <td>    0.008</td> <td>    0.793</td> <td> 0.428</td> <td>   -0.010</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>64</th>            <td>    0.0079</td> <td>    0.007</td> <td>    1.171</td> <td> 0.242</td> <td>   -0.005</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>65</th>            <td>   -0.0068</td> <td>    0.021</td> <td>   -0.318</td> <td> 0.751</td> <td>   -0.049</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>66</th>            <td>    0.0052</td> <td>    0.005</td> <td>    1.138</td> <td> 0.255</td> <td>   -0.004</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>67</th>            <td>   -0.0036</td> <td>    0.030</td> <td>   -0.122</td> <td> 0.903</td> <td>   -0.062</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>68</th>            <td>    0.0310</td> <td>    0.058</td> <td>    0.535</td> <td> 0.593</td> <td>   -0.083</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>69</th>            <td>    0.0104</td> <td>    0.007</td> <td>    1.472</td> <td> 0.141</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>70</th>            <td> 1.083e-17</td> <td> 6.86e-18</td> <td>    1.578</td> <td> 0.115</td> <td>-2.64e-18</td> <td> 2.43e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>71</th>            <td>    0.0007</td> <td>    0.003</td> <td>    0.202</td> <td> 0.840</td> <td>   -0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>72</th>            <td>    0.0007</td> <td>    0.003</td> <td>    0.202</td> <td> 0.840</td> <td>   -0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>73</th>            <td>   -0.0323</td> <td>    0.018</td> <td>   -1.804</td> <td> 0.072</td> <td>   -0.067</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>74</th>            <td>   -0.0090</td> <td>    0.004</td> <td>   -2.007</td> <td> 0.045</td> <td>   -0.018</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>75</th>            <td>    0.0022</td> <td>    0.021</td> <td>    0.103</td> <td> 0.918</td> <td>   -0.040</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>76</th>            <td>    0.0080</td> <td>    0.016</td> <td>    0.515</td> <td> 0.607</td> <td>   -0.023</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>77</th>            <td>    0.0080</td> <td>    0.016</td> <td>    0.515</td> <td> 0.607</td> <td>   -0.023</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>78</th>            <td>    0.0435</td> <td>    0.027</td> <td>    1.598</td> <td> 0.110</td> <td>   -0.010</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>79</th>            <td>    0.0044</td> <td>    0.008</td> <td>    0.581</td> <td> 0.562</td> <td>   -0.010</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>80</th>            <td>    0.0109</td> <td>    0.029</td> <td>    0.371</td> <td> 0.711</td> <td>   -0.047</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>81</th>            <td>    0.0170</td> <td>    0.012</td> <td>    1.410</td> <td> 0.159</td> <td>   -0.007</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>82</th>            <td>    0.0075</td> <td>    0.041</td> <td>    0.184</td> <td> 0.854</td> <td>   -0.072</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>83</th>            <td>    0.0002</td> <td>    0.009</td> <td>    0.024</td> <td> 0.981</td> <td>   -0.018</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>84</th>            <td>   -0.0200</td> <td>    0.009</td> <td>   -2.292</td> <td> 0.022</td> <td>   -0.037</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>85</th>            <td>   -0.0013</td> <td>    0.008</td> <td>   -0.152</td> <td> 0.880</td> <td>   -0.018</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>86</th>            <td>    0.0037</td> <td>    0.005</td> <td>    0.715</td> <td> 0.475</td> <td>   -0.006</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>87</th>            <td>   -0.0024</td> <td>    0.021</td> <td>   -0.114</td> <td> 0.909</td> <td>   -0.044</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>88</th>            <td>   -0.0009</td> <td>    0.004</td> <td>   -0.209</td> <td> 0.834</td> <td>   -0.009</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>89</th>            <td>   -0.0091</td> <td>    0.029</td> <td>   -0.318</td> <td> 0.751</td> <td>   -0.066</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>90</th>            <td>    0.0300</td> <td>    0.057</td> <td>    0.527</td> <td> 0.598</td> <td>   -0.082</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>91</th>            <td>   -0.0081</td> <td>    0.012</td> <td>   -0.699</td> <td> 0.485</td> <td>   -0.031</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>92</th>            <td>    0.0377</td> <td>    0.058</td> <td>    0.649</td> <td> 0.516</td> <td>   -0.076</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>93</th>            <td>    0.0019</td> <td>    0.021</td> <td>    0.089</td> <td> 0.929</td> <td>   -0.040</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>94</th>            <td>    0.0267</td> <td>    0.037</td> <td>    0.716</td> <td> 0.474</td> <td>   -0.047</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>95</th>            <td>   -0.1020</td> <td>    0.027</td> <td>   -3.721</td> <td> 0.000</td> <td>   -0.156</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>96</th>            <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>97</th>            <td>   -0.0296</td> <td>    0.058</td> <td>   -0.511</td> <td> 0.609</td> <td>   -0.143</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>98</th>            <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>99</th>            <td>   -0.0234</td> <td>    0.027</td> <td>   -0.873</td> <td> 0.383</td> <td>   -0.076</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>100</th>           <td>   -0.0199</td> <td>    0.020</td> <td>   -0.980</td> <td> 0.327</td> <td>   -0.060</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>101</th>           <td>   -0.0083</td> <td>    0.009</td> <td>   -0.905</td> <td> 0.366</td> <td>   -0.026</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>102</th>           <td>   -0.0039</td> <td>    0.004</td> <td>   -0.970</td> <td> 0.332</td> <td>   -0.012</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>33.703</td> <th>  Durbin-Watson:     </th> <td>   1.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  74.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.087</td> <th>  Prob(JB):          </th> <td>5.70e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.209</td> <th>  Cond. No.          </th> <td>1.07e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.75e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 중식 참여율   R-squared:                       0.813\n",
       "Model:                            OLS   Adj. R-squared:                  0.791\n",
       "Method:                 Least Squares   F-statistic:                     37.46\n",
       "Date:                Tue, 06 Jul 2021   Prob (F-statistic):          1.11e-313\n",
       "Time:                        01:40:50   Log-Likelihood:                 2268.1\n",
       "No. Observations:                1204   AIC:                            -4284.\n",
       "Df Residuals:                    1078   BIC:                            -3642.\n",
       "Df Model:                         125                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const             0.5854      0.025     23.082      0.000       0.536       0.635\n",
       "Covid19           0.1164      0.014      8.455      0.000       0.089       0.143\n",
       "점심강수량             0.0933      0.022      4.300      0.000       0.051       0.136\n",
       "PM10             -0.0166      0.009     -1.848      0.065      -0.034       0.001\n",
       "문화day            -0.0009      0.007     -0.117      0.907      -0.016       0.014\n",
       "본사출근자수           -0.4555      0.017    -27.411      0.000      -0.488      -0.423\n",
       "본사휴가율            -1.1819      0.051    -23.249      0.000      -1.282      -1.082\n",
       "본사출장율            -2.4385      0.158    -15.416      0.000      -2.749      -2.128\n",
       "본사재택근무율          -0.6353      0.062    -10.204      0.000      -0.757      -0.513\n",
       "시간외근무율            0.2022      0.026      7.691      0.000       0.151       0.254\n",
       "최고기온30+          -0.0026      0.006     -0.468      0.640      -0.013       0.008\n",
       "pre공휴일           -0.0029      0.008     -0.362      0.717      -0.018       0.013\n",
       "금                 0.0857      0.008     10.689      0.000       0.070       0.101\n",
       "목                 0.0848      0.006     13.935      0.000       0.073       0.097\n",
       "수                 0.1355      0.006     21.063      0.000       0.123       0.148\n",
       "월                 0.1796      0.006     29.796      0.000       0.168       0.191\n",
       "화                 0.0998      0.006     17.193      0.000       0.088       0.111\n",
       "10월               0.0746      0.005     13.991      0.000       0.064       0.085\n",
       "11월               0.0448      0.006      7.514      0.000       0.033       0.057\n",
       "12월               0.0210      0.007      3.113      0.002       0.008       0.034\n",
       "1월                0.0277      0.007      3.965      0.000       0.014       0.041\n",
       "2월                0.0560      0.007      8.338      0.000       0.043       0.069\n",
       "3월                0.0422      0.006      7.619      0.000       0.031       0.053\n",
       "4월                0.0388      0.005      7.397      0.000       0.029       0.049\n",
       "5월                0.0520      0.006      9.204      0.000       0.041       0.063\n",
       "6월                0.0434      0.007      6.554      0.000       0.030       0.056\n",
       "7월                0.0413      0.007      5.899      0.000       0.028       0.055\n",
       "8월                0.0818      0.008     10.239      0.000       0.066       0.097\n",
       "9월                0.0618      0.006      9.648      0.000       0.049       0.074\n",
       "1주차               0.1035      0.006     18.103      0.000       0.092       0.115\n",
       "2주차               0.1039      0.005     20.269      0.000       0.094       0.114\n",
       "3주차               0.0994      0.005     19.503      0.000       0.089       0.109\n",
       "4주차               0.0983      0.005     18.235      0.000       0.088       0.109\n",
       "5주차               0.0980      0.005     18.529      0.000       0.088       0.108\n",
       "6주차               0.0823      0.010      8.560      0.000       0.063       0.101\n",
       "평균기온_temp-10+     0.0654      0.014      4.712      0.000       0.038       0.093\n",
       "평균기온_temp-5+      0.0596      0.007      8.058      0.000       0.045       0.074\n",
       "평균기온_temp0+       0.0730      0.006     11.446      0.000       0.060       0.086\n",
       "평균기온_temp10+      0.0597      0.006     10.103      0.000       0.048       0.071\n",
       "평균기온_temp15+      0.0569      0.006      9.450      0.000       0.045       0.069\n",
       "평균기온_temp20+      0.0563      0.007      8.623      0.000       0.044       0.069\n",
       "평균기온_temp25+      0.0648      0.008      7.772      0.000       0.048       0.081\n",
       "평균기온_temp30+      0.0845      0.017      5.036      0.000       0.052       0.117\n",
       "평균기온_temp5+       0.0652      0.006     10.804      0.000       0.053       0.077\n",
       "4주x금요일           -0.0145      0.007     -2.102      0.036      -0.028      -0.001\n",
       "timedelta        -0.0014      0.002     -0.785      0.433      -0.005       0.002\n",
       "0                 0.0067      0.004      1.733      0.083      -0.001       0.014\n",
       "1                -0.0065      0.009     -0.720      0.472      -0.024       0.011\n",
       "2                -0.0064      0.010     -0.621      0.535      -0.026       0.014\n",
       "3                -0.0199      0.020     -0.980      0.327      -0.060       0.020\n",
       "4                -0.0029      0.008     -0.348      0.728      -0.019       0.013\n",
       "5                 0.0258      0.013      2.014      0.044       0.001       0.051\n",
       "6                -0.0138      0.011     -1.229      0.219      -0.036       0.008\n",
       "7             -3.473e-15   2.51e-16    -13.856      0.000   -3.96e-15   -2.98e-15\n",
       "8                 0.0052      0.010      0.545      0.586      -0.014       0.024\n",
       "9                -0.0143      0.010     -1.457      0.145      -0.034       0.005\n",
       "10               -0.0194      0.027     -0.715      0.475      -0.073       0.034\n",
       "11                0.0057      0.009      0.613      0.540      -0.013       0.024\n",
       "12                0.0120      0.013      0.911      0.362      -0.014       0.038\n",
       "13                0.0064      0.005      1.250      0.211      -0.004       0.017\n",
       "14               -0.0022      0.007     -0.334      0.739      -0.015       0.011\n",
       "15                0.0043      0.022      0.195      0.846      -0.039       0.047\n",
       "16               -0.0028      0.030     -0.096      0.924      -0.061       0.055\n",
       "17               -0.0004      0.060     -0.006      0.995      -0.118       0.118\n",
       "18             6.718e-16   8.01e-17      8.386      0.000    5.15e-16    8.29e-16\n",
       "19             2.714e-15   1.73e-16     15.691      0.000    2.37e-15    3.05e-15\n",
       "20                0.0059      0.002      2.638      0.008       0.002       0.010\n",
       "21                0.0059      0.002      2.638      0.008       0.002       0.010\n",
       "22                0.0012      0.002      0.549      0.583      -0.003       0.005\n",
       "23                0.0053      0.005      1.106      0.269      -0.004       0.015\n",
       "24               -0.0211      0.011     -1.878      0.061      -0.043       0.001\n",
       "25                0.0067      0.004      1.733      0.083      -0.001       0.014\n",
       "26                0.0012      0.026      0.044      0.965      -0.050       0.053\n",
       "27                0.0332      0.040      0.825      0.410      -0.046       0.112\n",
       "28               -0.0017      0.024     -0.071      0.943      -0.049       0.045\n",
       "29                0.0078      0.013      0.579      0.563      -0.019       0.034\n",
       "30               -0.0219      0.035     -0.627      0.531      -0.091       0.047\n",
       "31               -0.0056      0.008     -0.749      0.454      -0.020       0.009\n",
       "32                0.0053      0.017      0.317      0.751      -0.027       0.038\n",
       "33                0.0118      0.010      1.182      0.237      -0.008       0.031\n",
       "34                0.0068      0.037      0.186      0.853      -0.065       0.079\n",
       "35               -0.0056      0.008     -0.702      0.483      -0.021       0.010\n",
       "36               -0.0036      0.025     -0.145      0.885      -0.053       0.046\n",
       "37                0.0059      0.006      0.932      0.352      -0.007       0.018\n",
       "38               -0.0078      0.027     -0.287      0.774      -0.061       0.046\n",
       "39               -0.0103      0.011     -0.925      0.355      -0.032       0.012\n",
       "40                0.0211      0.024      0.889      0.374      -0.025       0.068\n",
       "41                0.0035      0.005      0.720      0.472      -0.006       0.013\n",
       "42               -0.0044      0.005     -0.879      0.379      -0.014       0.005\n",
       "43               -0.0079      0.005     -1.565      0.118      -0.018       0.002\n",
       "44                0.0012      0.002      0.549      0.583      -0.003       0.005\n",
       "45               -0.0064      0.010     -0.621      0.535      -0.026       0.014\n",
       "46               -0.0012      0.019     -0.064      0.949      -0.038       0.036\n",
       "47                0.0216      0.029      0.736      0.462      -0.036       0.079\n",
       "48               -0.0041      0.027     -0.152      0.879      -0.057       0.049\n",
       "49                0.0552      0.037      1.484      0.138      -0.018       0.128\n",
       "50               -0.0049      0.008     -0.590      0.555      -0.021       0.011\n",
       "51               -0.0192      0.009     -2.132      0.033      -0.037      -0.002\n",
       "52                0.0083      0.005      1.620      0.106      -0.002       0.018\n",
       "53               -0.0003      0.008     -0.039      0.969      -0.017       0.016\n",
       "54                0.0080      0.006      1.423      0.155      -0.003       0.019\n",
       "55               -0.0130      0.021     -0.622      0.534      -0.054       0.028\n",
       "56             1.755e-05      0.005      0.004      0.997      -0.009       0.009\n",
       "57               -0.0177      0.032     -0.560      0.576      -0.080       0.044\n",
       "58                0.0224      0.058      0.385      0.701      -0.092       0.136\n",
       "59             1.044e-17   2.06e-17      0.508      0.612   -2.99e-17    5.08e-17\n",
       "60                0.0131      0.010      1.266      0.206      -0.007       0.033\n",
       "61                0.0101      0.009      1.159      0.247      -0.007       0.027\n",
       "62               -0.0144      0.009     -1.632      0.103      -0.032       0.003\n",
       "63                0.0067      0.008      0.793      0.428      -0.010       0.023\n",
       "64                0.0079      0.007      1.171      0.242      -0.005       0.021\n",
       "65               -0.0068      0.021     -0.318      0.751      -0.049       0.035\n",
       "66                0.0052      0.005      1.138      0.255      -0.004       0.014\n",
       "67               -0.0036      0.030     -0.122      0.903      -0.062       0.055\n",
       "68                0.0310      0.058      0.535      0.593      -0.083       0.145\n",
       "69                0.0104      0.007      1.472      0.141      -0.003       0.024\n",
       "70             1.083e-17   6.86e-18      1.578      0.115   -2.64e-18    2.43e-17\n",
       "71                0.0007      0.003      0.202      0.840      -0.006       0.007\n",
       "72                0.0007      0.003      0.202      0.840      -0.006       0.007\n",
       "73               -0.0323      0.018     -1.804      0.072      -0.067       0.003\n",
       "74               -0.0090      0.004     -2.007      0.045      -0.018      -0.000\n",
       "75                0.0022      0.021      0.103      0.918      -0.040       0.044\n",
       "76                0.0080      0.016      0.515      0.607      -0.023       0.039\n",
       "77                0.0080      0.016      0.515      0.607      -0.023       0.039\n",
       "78                0.0435      0.027      1.598      0.110      -0.010       0.097\n",
       "79                0.0044      0.008      0.581      0.562      -0.010       0.019\n",
       "80                0.0109      0.029      0.371      0.711      -0.047       0.069\n",
       "81                0.0170      0.012      1.410      0.159      -0.007       0.041\n",
       "82                0.0075      0.041      0.184      0.854      -0.072       0.087\n",
       "83                0.0002      0.009      0.024      0.981      -0.018       0.018\n",
       "84               -0.0200      0.009     -2.292      0.022      -0.037      -0.003\n",
       "85               -0.0013      0.008     -0.152      0.880      -0.018       0.015\n",
       "86                0.0037      0.005      0.715      0.475      -0.006       0.014\n",
       "87               -0.0024      0.021     -0.114      0.909      -0.044       0.039\n",
       "88               -0.0009      0.004     -0.209      0.834      -0.009       0.007\n",
       "89               -0.0091      0.029     -0.318      0.751      -0.066       0.047\n",
       "90                0.0300      0.057      0.527      0.598      -0.082       0.142\n",
       "91               -0.0081      0.012     -0.699      0.485      -0.031       0.015\n",
       "92                0.0377      0.058      0.649      0.516      -0.076       0.152\n",
       "93                0.0019      0.021      0.089      0.929      -0.040       0.044\n",
       "94                0.0267      0.037      0.716      0.474      -0.047       0.100\n",
       "95               -0.1020      0.027     -3.721      0.000      -0.156      -0.048\n",
       "96                     0          0        nan        nan           0           0\n",
       "97               -0.0296      0.058     -0.511      0.609      -0.143       0.084\n",
       "98                     0          0        nan        nan           0           0\n",
       "99               -0.0234      0.027     -0.873      0.383      -0.076       0.029\n",
       "100              -0.0199      0.020     -0.980      0.327      -0.060       0.020\n",
       "101              -0.0083      0.009     -0.905      0.366      -0.026       0.010\n",
       "102              -0.0039      0.004     -0.970      0.332      -0.012       0.004\n",
       "==============================================================================\n",
       "Omnibus:                       33.703   Durbin-Watson:                   1.468\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.807\n",
       "Skew:                           0.087   Prob(JB):                     5.70e-17\n",
       "Kurtosis:                       4.209   Cond. No.                     1.07e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.75e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.OLS(train_y_lunch, train_x_lunch).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_lunch = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "model2_lunch = XGBRegressor(objective='reg:squarederror', n_estimators=100,\n",
    "                            learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                            colsample_bytree=1, max_depth=7, random_state=42)\n",
    "model3_lunch = model3 = Ridge(alpha=2.5, fit_intercept=True, random_state=42, normalize=False)\n",
    "model4_lunch = BaggingRegressor(random_state=30)\n",
    "model6_lunch = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "model1_dinner = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "model2_dinner = XGBRegressor(objective='reg:squarederror', n_estimators=100,\n",
    "                             learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                             colsample_bytree=1, max_depth=7, random_state=42)\n",
    "model3_dinner = model3 = Ridge(alpha=2.5, fit_intercept=True, random_state=42, normalize=False)\n",
    "model4_dinner = BaggingRegressor(random_state=30)\n",
    "model6_dinner = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_lunch.fit(train_x_lunch, train_y_lunch) \n",
    "model2_lunch.fit(train_x_lunch, train_y_lunch)    \n",
    "model3_lunch.fit(train_x_lunch, train_y_lunch) \n",
    "model4_lunch.fit(train_x_lunch, train_y_lunch) \n",
    "model6_lunch.fit(train_x_lunch, train_y_lunch) \n",
    "model1_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "model2_dinner.fit(train_x_dinner, train_y_dinner)         \n",
    "model3_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "model4_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "model6_dinner.fit(train_x_dinner, train_y_dinner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lunch = 0.2 * model1_lunch.predict(test_x_lunch) + 0.3 * model2_lunch.predict(test_x_lunch) + \\\n",
    "             0.1 * model4_lunch.predict(test_x_lunch) + 0.4 * model6_lunch.predict(test_x_lunch)\n",
    "\n",
    "\n",
    "pred_dinner = 0.2 * model1_dinner.predict(test_x_dinner) + 0.3 * model2_dinner.predict(test_x_dinner) + \\\n",
    "              0.1 * model4_dinner.predict(test_x_dinner) + 0.4 * model6_dinner.predict(test_x_dinner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['중식계'] = (pred_lunch * whole_df['본사출근자수'][-50:]).values.round()\n",
    "sub['석식계'] = (pred_dinner * whole_df['본사출근자수'][-50:]).values.round()\n",
    "sub.to_csv('submission_Ensemble_includingMenu_4models_NewFeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, 0.05, .08], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'subsample': [0.75],\n",
    "              'colsample_bytree': [1],\n",
    "              'n_estimators': [500],\n",
    "              'random_state' : [42]}\n",
    "\n",
    "params_RF = {\n",
    "             \"n_estimators\" : [10,50,100],\n",
    "             \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n",
    "             \"bootstrap\"    : [True, False],\n",
    "             \"random_state\" : [42],\n",
    "             \"n_jobs\" : [-1]\n",
    "             }\n",
    "\n",
    "params_BG = {'n_jobs' : [-1],\n",
    "             'random_state' : [42]}\n",
    "params_Ridge = {'alpha' : [2.5],\n",
    "                'random_state' : [42],\n",
    "                'normalize' : [False],\n",
    "                'fit_intercept' : [True]}\n",
    "\n",
    "params_GB =  {'learning_rate': [.03, 0.05, .08], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'n_estimators': [500],\n",
    "              'random_state' : [42],\n",
    "              'min_samples_leaf':[3], \n",
    "              'max_features':[1.0] }\n",
    "\n",
    "model1 = RandomForestRegressor()\n",
    "model2 = XGBRegressor()\n",
    "model3 = Ridge()\n",
    "model4 = BaggingRegressor()\n",
    "model6 = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "model1_lunch = GridSearchCV(model1, params_RF, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "model2_lunch = GridSearchCV(model2, params_XGB, scoring='neg_mean_absolute_error')\n",
    "\n",
    "model3_lunch = GridSearchCV(model3, params_Ridge, scoring='neg_mean_absolute_error')\n",
    "\n",
    "model4_lunch = GridSearchCV(model4, params_BG, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "model6_lunch = GridSearchCV(model6, params_GB, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "model1_dinner = GridSearchCV(model1, params_RF, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "model2_dinner = GridSearchCV(model2, params_XGB, scoring='neg_mean_absolute_error')\n",
    "\n",
    "model3_dinner = GridSearchCV(model3, params_Ridge, scoring='neg_mean_absolute_error')\n",
    "\n",
    "model4_dinner = GridSearchCV(model4, params_BG, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "model6_dinner = GridSearchCV(model6, params_GB, scoring = 'neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "dinner done\n"
     ]
    }
   ],
   "source": [
    "model1_lunch.fit(train_x_lunch, train_y_lunch)\n",
    "print('done')\n",
    "model2_lunch.fit(train_x_lunch, train_y_lunch)\n",
    "model2_lunch = model2_lunch.best_estimator_\n",
    "print('done')\n",
    "model3_lunch.fit(train_x_lunch, train_y_lunch)\n",
    "print('done')\n",
    "model4_lunch.fit(train_x_lunch, train_y_lunch)\n",
    "print('done')\n",
    "model6_lunch.fit(train_x_lunch, train_y_lunch)\n",
    "\n",
    "\n",
    "print('lunch done')\n",
    "\n",
    "model1_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "print('done')\n",
    "model2_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "model2_dinner = model2_dinner.best_estimator_\n",
    "print('done')\n",
    "model3_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "print('done')\n",
    "model4_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "print('done')\n",
    "model6_dinner.fit(train_x_dinner, train_y_dinner)\n",
    "\n",
    "print('dinner done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lunch = 0.2 * model1_lunch.predict(test_x_lunch) + 0.25 * model2_lunch.predict(test_x_lunch) + 0.05 * model3_lunch.predict(test_x_lunch) + 0.1 * model4_lunch.predict(test_x_lunch) + 0.4 * model6_lunch.predict(test_x_lunch)\n",
    "\n",
    "pred_dinner = 0.2 * model1_dinner.predict(test_x_dinner) + 0.25 * model2_dinner.predict(test_x_dinner) + 0.05 * model3_dinner.predict(test_x_dinner) + 0.1 * model4_dinner.predict(test_x_dinner) + 0.4 * model6_dinner.predict(test_x_dinner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
